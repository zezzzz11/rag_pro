# Backend Configuration
SECRET_KEY=change-this-secret-key-in-production
ACCESS_TOKEN_EXPIRE_MINUTES=10080

# Ollama Configuration
# Model to use (lightweight models recommended for Docker)
OLLAMA_MODEL=qwen2.5:0.5b

# Available lightweight models:
# - qwen2.5:0.5b (397 MB) - Fastest, great for testing
# - llama3.2:1b (1.3 GB) - Good balance
# - phi3:mini (2.2 GB) - Microsoft's efficient model
# - gemma2:2b (1.6 GB) - Google's efficient model

# Ollama URL (automatically set by docker-compose)
# OLLAMA_BASE_URL=http://ollama:11434

# CORS Configuration
# For local development: http://localhost:3000
# For remote access: http://your-server-ip:3000 or http://your-domain.com:3000
# Multiple origins (comma-separated): http://localhost:3000,http://192.168.1.100:3000
ALLOWED_ORIGINS=http://localhost:3000

# Frontend Configuration
# For local development: http://localhost:8000
# For remote access from another machine: http://your-server-ip:8000 or http://your-domain.com:8000
# Example: NEXT_PUBLIC_API_URL=http://192.168.1.100:8000
NEXT_PUBLIC_API_URL=http://localhost:8000
