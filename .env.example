# Backend Configuration
SECRET_KEY=change-this-secret-key-in-production
ACCESS_TOKEN_EXPIRE_MINUTES=10080

# Ollama Configuration
# Model to use (lightweight models recommended for Docker)
OLLAMA_MODEL=qwen2.5:0.5b

# Available lightweight models:
# - qwen2.5:0.5b (397 MB) - Fastest, great for testing
# - llama3.2:1b (1.3 GB) - Good balance
# - phi3:mini (2.2 GB) - Microsoft's efficient model
# - gemma2:2b (1.6 GB) - Google's efficient model

# Ollama URL (automatically set by docker-compose)
# OLLAMA_BASE_URL=http://ollama:11434

# CORS Configuration
# Allow requests from Next.js frontend (server-side API routes)
# In Docker: uses container name, In local dev: uses localhost
# Default: http://rag-pro-frontend:3000,http://localhost:3000
ALLOWED_ORIGINS=http://rag-pro-frontend:3000,http://localhost:3000

# Backend URL for Next.js server-side API routes
# In Docker: uses container name (http://rag-pro-backend:8000)
# In local dev: uses localhost (http://localhost:8000)
# Default: http://localhost:8000 (for local dev)
BACKEND_URL=http://localhost:8000

# NOTE: Clients only need to access the frontend at port 3000
# All API calls are proxied through Next.js, no need to expose backend port 8000 externally
